{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(1337) # for reproducibility\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1337)\n",
    "#from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import SpatialDropout2D, Activation\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "\n",
    "# Number of image channels (for example 3 in case of RGB, or 1 for grayscale images)\n",
    "INPUT_CHANNELS = 5\n",
    "# Number of output masks (1 in case you predict only one type of objects)\n",
    "OUTPUT_MASK_CHANNELS = 1\n",
    "#seed = 42\n",
    "#random.seed = seed\n",
    "#np.random.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
    "\n",
    "\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return -jacard_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv_layer(x, size, dropout=0.0, batch_norm=True):\n",
    "    if K.image_data_format() == 'th':\n",
    "        axis = 1\n",
    "    else:\n",
    "        axis = 3\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    if dropout > 0:\n",
    "        conv = SpatialDropout2D(dropout)(conv)\n",
    "    return conv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    dice_list = [s for s in history.history.keys() if 'dice' in s and 'val' not in s]\n",
    "    val_dice_list = [s for s in history.history.keys() if 'dice' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    ## Dice Coefficient\n",
    "    plt.figure(2)\n",
    "    for l in dice_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training Dice Coefficient (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_dice_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation Dice Coefficient (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Dice Coefficient')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Dice Coefficient')\n",
    "    plt.legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(3)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZF_UNET_224(dropout_val=0.2, weights=None):\n",
    "    if K.image_data_format() == 'th':\n",
    "        inputs = Input((INPUT_CHANNELS, 224, 224))\n",
    "        axis = 1\n",
    "    else:\n",
    "        inputs = Input((224, 224, INPUT_CHANNELS))\n",
    "        axis = 3\n",
    "    filters = 32\n",
    "\n",
    "    conv_224 = double_conv_layer(inputs, filters)\n",
    "    pool_112 = MaxPooling2D(pool_size=(2, 2))(conv_224)\n",
    "\n",
    "    conv_112 = double_conv_layer(pool_112, 2*filters)\n",
    "    pool_56 = MaxPooling2D(pool_size=(2, 2))(conv_112)\n",
    "\n",
    "    conv_56 = double_conv_layer(pool_56, 4*filters)\n",
    "    pool_28 = MaxPooling2D(pool_size=(2, 2))(conv_56)\n",
    "\n",
    "    conv_28 = double_conv_layer(pool_28, 8*filters)\n",
    "    pool_14 = MaxPooling2D(pool_size=(2, 2))(conv_28)\n",
    "\n",
    "    conv_14 = double_conv_layer(pool_14, 16*filters)\n",
    "    pool_7 = MaxPooling2D(pool_size=(2, 2))(conv_14)\n",
    "\n",
    "    conv_7 = double_conv_layer(pool_7, 32*filters)\n",
    "\n",
    "    up_14 = concatenate([UpSampling2D(size=(2, 2))(conv_7), conv_14], axis=axis)\n",
    "    up_conv_14 = double_conv_layer(up_14, 16*filters)\n",
    "\n",
    "    up_28 = concatenate([UpSampling2D(size=(2, 2))(up_conv_14), conv_28], axis=axis)\n",
    "    up_conv_28 = double_conv_layer(up_28, 8*filters)\n",
    "\n",
    "    up_56 = concatenate([UpSampling2D(size=(2, 2))(up_conv_28), conv_56], axis=axis)\n",
    "    up_conv_56 = double_conv_layer(up_56, 4*filters)\n",
    "\n",
    "    up_112 = concatenate([UpSampling2D(size=(2, 2))(up_conv_56), conv_112], axis=axis)\n",
    "    up_conv_112 = double_conv_layer(up_112, 2*filters)\n",
    "\n",
    "    up_224 = concatenate([UpSampling2D(size=(2, 2))(up_conv_112), conv_224], axis=axis)\n",
    "    up_conv_224 = double_conv_layer(up_224, filters, dropout_val)\n",
    "\n",
    "    conv_final = Conv2D(OUTPUT_MASK_CHANNELS, (1, 1))(up_conv_224)\n",
    "    conv_final = Activation('sigmoid')(conv_final)\n",
    "\n",
    "    model = Model(inputs, conv_final, name=\"ZF_UNET_224\")\n",
    "\n",
    "    #if weights == 'generator' and axis == 3 and INPUT_CHANNELS == 3 and OUTPUT_MASK_CHANNELS == 1:\n",
    "    ##    weights_path = get_file(\n",
    "     #       'zf_unet_224_weights_tf_dim_ordering_tf_generator.h5',\n",
    "     #       ZF_UNET_224_WEIGHT_PATH,\n",
    "     #       cache_subdir='models',\n",
    "     #       file_hash='203146f209baf34ac0d793e1691f1ab7')\n",
    "     #   model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_validation = np.load(\"X_validation_ALL_RT224cti.npy\")\n",
    "#Y_validation = np.load(\"Y_validation_ALL_RT224cti.npy\")\n",
    "X_test = np.load(\"X_test224cti.npy\")\n",
    "Y_test = np.load(\"Y_test224.npy\")\n",
    "#X_validation = X_validation.astype('uint8')\n",
    "#Y_validation = Y_validation.astype('uint8')\n",
    "#X_test = X_test.astype('uint8')\n",
    "#Y_test = Y_test.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_validation = X_validation/255.0\n",
    "#Y_validation = Y_validation/255.0\n",
    "#X_test = X_test/255.0\n",
    "#Y_test = Y_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"13X_train224.npy\")\n",
    "Y_train = np.load(\"13Y_train224.npy\")\n",
    "X_train = X_train.astype('uint8')\n",
    "Y_train = Y_train.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ZF_UNET_224()\n",
    "learning_rate =0.0001\n",
    "patience = 20\n",
    "model.compile(optimizer=Adam(lr=learning_rate),loss = dice_coef_loss,metrics=[dice_coef,'accuracy'])\n",
    "callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-9, epsilon=0.00001, verbose=1, mode='min'),\n",
    "        EarlyStopping(monitor='val_loss', patience=patience, verbose=0),\n",
    "        ModelCheckpoint('unetLr03.h5', monitor='val_loss', save_best_only=True, verbose=0),\n",
    "    ]\n",
    "# Fit model\n",
    "results_03 = model.fit(X_train, Y_train, validation_split=0.2, batch_size=16, epochs=50,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(results_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"SL_results_143.npy\",results_03.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('attempt3preseparation.h5')\n",
    "model.save_weights(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#why this error\n",
    "#ttmodel= load_model('weights.h5',compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"2X_test224cti.npy\")\n",
    "Y_test = np.load(\"2Y_test224.npy\")\n",
    "X_test = X_test.astype('uint8')\n",
    "Y_test = Y_test.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,Y_test.shape[0]):\n",
    "    print(str(i)+\": \"+str(np.sum(Y_test[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,preds_test_t.shape[0]):\n",
    "    print(str(i)+\": \"+str(np.sum(preds_test_t[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds_test_t.shape=(132,224,224,1)\n",
    "print(preds_test_t.shape)\n",
    "print(np.max(preds_test[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.load(\"13Y_train224.npy\")\n",
    "Y_train = Y_train.astype('uint8')\n",
    "#Y_test = np.load(\"Y_test224.npy\")\n",
    "#Y_test= Y_train.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappedResult = []\n",
    "for i in range(0,X_train.shape[0]):\n",
    "    curGT = Y_train[i]\n",
    "    curPD = preds_test_t[i]\n",
    "    values = curGT.copy()\n",
    "    #print(curGT.shape)\n",
    "    #print(curPD.shape)\n",
    "    for x in range(0,IMG_WIDTH):\n",
    "        for y in range(0,IMG_WIDTH):\n",
    "            if curGT[x,y]==0 and curPD[x,y]==0:\n",
    "                #print(\"here\")\n",
    "                values[x,y] = 0\n",
    "            elif curGT[x,y]==0 and curPD[x,y]==1:\n",
    "                #print(\"here1\")\n",
    "                values[x,y] = 1\n",
    "            elif curGT[x,y]==1 and curPD[x,y]==0:\n",
    "                #print(\"here2\")\n",
    "                values[x,y] = 2\n",
    "            elif curGT[x,y]==1 and curPD[x,y]==1:\n",
    "                values[x,y] = 3\n",
    "    mappedResult.append(values)\n",
    "    \n",
    "mappedResult = np.asarray(mappedResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappedResult.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(mappedResult.shape[0]):\n",
    "    print(str(i)+\": \"+str(np.max(mappedResult[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 135\n",
    "#imshow(np.squeeze(X_train[ix]))\n",
    "#plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]),cmap=plt.cm.Spectral)\n",
    "plt.show()\n",
    "#imshow(np.squeeze(preds_test_t[ix]),cmap=plt.cm.Spectral)\n",
    "#plt.show()\n",
    "imshow(np.squeeze(mappedResult[ix]),cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_mod = preds_test_t\n",
    "preds_test_mod.shape = preds_test_mod.shape[0] * 224*224 ,1\n",
    "preds_test_mod2  = preds_test_mod.tolist()\n",
    "predictionlist = [item for sublist in preds_test_mod2 for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth = Y_train\n",
    "groundtruth.shape = groundtruth.shape[0] * 224*224 ,1\n",
    "groundtruth  = groundtruth.tolist()\n",
    "groundtruthlist = [item for sublist in groundtruth for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(groundtruthlist, predictionlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm,classes=[\"Dryland\",\"Wetland\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score,recall_score\n",
    "print(f1_score(groundtruthlist, predictionlist, average='macro'))\n",
    "print(precision_score(groundtruthlist, predictionlist,pos_label=1))\n",
    "print(precision_score(groundtruthlist, predictionlist,pos_label=0))\n",
    "print(recall_score(groundtruthlist, predictionlist,pos_label=1))\n",
    "print(recall_score(groundtruthlist, predictionlist,pos_label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new confusion Matrix with cti\n",
    "from sklearn.metrics import f1_score, precision_score,recall_score\n",
    "print(f1_score(groundtruthlist, predictionlist, average='macro'))\n",
    "print(f1_score(groundtruthlist, predictionlist,pos_label=1))\n",
    "print(f1_score(groundtruthlist, predictionlist,pos_label=0))\n",
    "print(precision_score(groundtruthlist, predictionlist,pos_label=1))\n",
    "print(precision_score(groundtruthlist, predictionlist,pos_label=0))\n",
    "print(recall_score(groundtruthlist, predictionlist,pos_label=1))\n",
    "print(recall_score(groundtruthlist, predictionlist,pos_label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(groundtruthlist, predictionlist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(groundtruthlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(groundtruthlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(groundtruthlist)-sum(groundtruthlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(groundtruthlist, predictionlist, pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(groundtruthlist, predictionlist, pos_label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = f1_score(groundtruthlist, predictionlist, pos_label=1)\n",
    "b= f1_score(groundtruthlist, predictionlist, pos_label=0)\n",
    "c =(a+b)/2\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('unetLr03.h5', custom_objects={'dice_coef': dice_coef,'dice_coef_loss':dice_coef_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappedResult = []\n",
    "for i in range(0,X_train.shape[0]):\n",
    "    curGT = Y_train[i]\n",
    "    curPD = preds_test_t[i]\n",
    "    values = curGT.copy()\n",
    "    for x in range(0,IMG_WIDTH):\n",
    "        for y in range(0,IMG_WIDTH):\n",
    "            if curGT[x,y]==0 and curPD[x,y]==0:\n",
    "                #print(\"here\")\n",
    "                values[x,y] = 0\n",
    "            elif curGT[x,y]==0 and curPD[x,y]==1:\n",
    "                #print(\"here1\")\n",
    "                values[x,y] = 1\n",
    "            elif curGT[x,y]==1 and curPD[x,y]==0:\n",
    "                #print(\"here2\")\n",
    "                values[x,y] = 2\n",
    "            elif curGT[x,y]==1 and curPD[x,y]==1:\n",
    "                values[x,y] = 3\n",
    "    mappedResult.append(values)\n",
    "    \n",
    "mappedResult = np.asarray(mappedResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TestMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.load(\"Y_testMap.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappedResult = np.load(\"TestmappedResult.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Y_test.astype('uint8')\n",
    "mappedResult =mappedResult.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(0,1000):\n",
    "#ix = 75\n",
    "#imshow(np.squeeze(X_train[ix]))\n",
    "#plt.show()\n",
    "    if(Y_test[ix].sum()>500):\n",
    "        print(ix)\n",
    "        imshow(np.squeeze(Y_test[ix]),cmap=plt.cm.Spectral)\n",
    "        plt.show()\n",
    "#imshow(np.squeeze(preds_test_t[ix]),cmap=plt.cm.Spectral)\n",
    "#plt.show()\n",
    "    #imshow(np.squeeze(mappedResult[ix]),cmap=plt.cm.Spectral)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappedResult.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testRGB = np.load(\"X_testRGB.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "ix=random.randint(300,900)\n",
    "imshow(X_testRGB[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_test[ix]),cmap=plt.cm.Spectral)\n",
    "plt.show()\n",
    "imshow(np.squeeze(mappedResult[ix]),cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
